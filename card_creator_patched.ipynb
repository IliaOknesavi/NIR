{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import ctgan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ctgan import CTGAN\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Card:\n",
    "    dataset: str\n",
    "    encoding: str\n",
    "    target: str\n",
    "    dataset_path: str\n",
    "    model_path: str\n",
    "    schedule_path: str\n",
    "    real_data: pd.DataFrame\n",
    "    synt_data: pd.DataFrame\n",
    "    jensen_shannon_divergence: pd.DataFrame\n",
    "    mean_jsd: float\n",
    "    logistic_real_score: float\n",
    "    logistic_synt_score: float\n",
    "    xgb_real_score: float\n",
    "    xgb_synt_score: float\n",
    "\n",
    "    def __init__(self, dataset: str, encoding: str, target: str, dataset_path: str, model_path: str, schedule_path: str):\n",
    "        self.dataset = dataset\n",
    "        self.encoding = encoding\n",
    "        self.target = target\n",
    "        self.dataset_path = dataset_path\n",
    "        self.model_path = model_path\n",
    "        self.schedule_path = schedule_path\n",
    "        self.model = ctgan.CTGAN.load(model_path)\n",
    "        self.real_data = pd.read_csv(dataset_path)\n",
    "        self.synt_data = self.model.sample(len(self.real_data))\n",
    "        self.jensen_shannon_divergence = pd.DataFrame()\n",
    "        self.mean_jsd = 0.0\n",
    "        self.logistic_real_score = 0.0\n",
    "        self.logistic_synt_score = 0.0\n",
    "        self.xgb_real_score = 0.0\n",
    "        self.xgb_synt_score = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def calculate_distributions(p_series: pd.Series, q_series: pd.Series):\n",
    "    \"\"\"\n",
    "    Вычисляет распределения вероятностей для двух серий (колонок) pandas.\n",
    "    Возвращает p, q на общем наборе уникальных значений.\n",
    "    \"\"\"\n",
    "    all_values = pd.Index(p_series.unique()).union(q_series.unique())\n",
    "    p_dist = p_series.value_counts(normalize=True).reindex(all_values, fill_value=0)\n",
    "    q_dist = q_series.value_counts(normalize=True).reindex(all_values, fill_value=0)\n",
    "    return p_dist, q_dist\n",
    "\n",
    "\n",
    "def calculate_metrics(p_df: pd.DataFrame, q_df: pd.DataFrame, skip_col: list[str] | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычисляет JSD дивергенцию для каждой колонки.\n",
    "    \"\"\"\n",
    "    skip_col = skip_col or []\n",
    "    metrics = []\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    for col in p_df.columns:\n",
    "        if col not in q_df.columns or col in skip_col:\n",
    "            continue\n",
    "\n",
    "        p, q = calculate_distributions(p_df[col], q_df[col])\n",
    "        p_nonzero = p[p > 0]\n",
    "        q_nonzero = q[q > 0]\n",
    "\n",
    "        m = 0.5 * (p + q)\n",
    "        m_smooth = m + epsilon\n",
    "\n",
    "        kl_p_m = np.sum(p_nonzero * np.log2(p_nonzero / m_smooth[p_nonzero.index]))\n",
    "        kl_q_m = np.sum(q_nonzero * np.log2(q_nonzero / m_smooth[q_nonzero.index]))\n",
    "        jensen_shannon_divergence = 0.5 * kl_p_m + 0.5 * kl_q_m\n",
    "\n",
    "        metrics.append({\n",
    "            \"column\": col,\n",
    "            \"jensen_shannon_divergence\": jensen_shannon_divergence,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics)[[\"column\", \"jensen_shannon_divergence\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "# --- Utility metrics ---\n",
    "def encode_targets(y_real: pd.Series, y_synt: pd.Series):\n",
    "    if y_real.empty:\n",
    "        return y_real, y_synt\n",
    "    sample = y_real.iloc[0]\n",
    "    if isinstance(sample, str) or y_real.dtype == object:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(pd.concat([y_real, y_synt], ignore_index=True))\n",
    "        return pd.Series(encoder.transform(y_real), index=y_real.index), pd.Series(encoder.transform(y_synt), index=y_synt.index)\n",
    "    return y_real, y_synt\n",
    "\n",
    "\n",
    "def evaluate_card(card: Card) -> None:\n",
    "    X_real = card.real_data.drop(columns=[card.target])\n",
    "    y_real = card.real_data[card.target]\n",
    "    X_synt = card.synt_data.drop(columns=[card.target])\n",
    "    y_synt = card.synt_data[card.target]\n",
    "\n",
    "    y_real_enc, y_synt_enc = encode_targets(y_real, y_synt)\n",
    "\n",
    "    X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "        X_real, y_real_enc, test_size=0.5, random_state=42, stratify=y_real_enc\n",
    "    )\n",
    "    X_train_synt, _, y_train_synt, _ = train_test_split(\n",
    "        X_synt, y_synt_enc, test_size=0.5, random_state=42, stratify=y_synt_enc\n",
    "    )\n",
    "\n",
    "    lr_params = dict(solver=\"saga\", max_iter=20000, random_state=42)\n",
    "    clf_real = make_pipeline(StandardScaler(), LogisticRegression(**lr_params))\n",
    "    clf_real.fit(X_train_real, y_train_real)\n",
    "    y_pred_real = clf_real.predict(X_test_real)\n",
    "    card.logistic_real_score = accuracy_score(y_test_real, y_pred_real)\n",
    "\n",
    "    clf_synt = make_pipeline(StandardScaler(), LogisticRegression(**lr_params))\n",
    "    clf_synt.fit(X_train_synt, y_train_synt)\n",
    "    y_pred_synt = clf_synt.predict(X_test_real)\n",
    "    card.logistic_synt_score = accuracy_score(y_test_real, y_pred_synt)\n",
    "\n",
    "    xgb_params = dict(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "    xgb_real = XGBClassifier(**xgb_params)\n",
    "    xgb_real.fit(X_train_real, y_train_real)\n",
    "    xgb_pred_real = xgb_real.predict(X_test_real)\n",
    "    card.xgb_real_score = accuracy_score(y_test_real, xgb_pred_real)\n",
    "\n",
    "    xgb_synt = XGBClassifier(**xgb_params)\n",
    "    xgb_synt.fit(X_train_synt, y_train_synt)\n",
    "    xgb_pred_synt = xgb_synt.predict(X_test_real)\n",
    "    card.xgb_synt_score = accuracy_score(y_test_real, xgb_pred_synt)\n",
    "\n",
    "    card.jensen_shannon_divergence = calculate_metrics(\n",
    "        card.real_data,\n",
    "        card.synt_data,\n",
    "        skip_col=[card.target, \"Id\", \"ID\", \"id\", \"identifier\"],\n",
    "    )\n",
    "    if not card.jensen_shannon_divergence.empty:\n",
    "        card.mean_jsd = float(card.jensen_shannon_divergence[\"jensen_shannon_divergence\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_FILE_SUFFIX = {\n",
    "    \"original\": \"original\",\n",
    "    \"one_hot_encoding\": \"ohe\",\n",
    "    \"label_encoding\": \"label\",\n",
    "    \"frequency_encoding\": \"frequency\",\n",
    "}\n",
    "\n",
    "ENCODING_LABELS = {\n",
    "    \"original\": \"Original\",\n",
    "    \"one_hot_encoding\": \"One-hot\",\n",
    "    \"label_encoding\": \"Label\",\n",
    "    \"frequency_encoding\": \"Frequency\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_registry(registry_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(registry_path)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    df[\"dataset_name\"] = df[\"dataset_name\"].str.strip()\n",
    "    df[\"target\"] = df[\"target\"].str.strip()\n",
    "    df[\"dataset_csv\"] = df[\"dataset_csv\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_cards_from_registry(registry_path: str) -> Dict[str, List[Card]]:\n",
    "    registry = load_registry(registry_path)\n",
    "    cards: Dict[str, List[Card]] = defaultdict(list)\n",
    "\n",
    "    for _, row in registry.iterrows():\n",
    "        dataset = row[\"dataset_name\"]\n",
    "        target = row[\"target\"]\n",
    "        dataset_csv = str(row[\"dataset_csv\"])\n",
    "        dataset_root = Path(dataset_csv).parent\n",
    "\n",
    "        for encoding, suffix in ENCODING_FILE_SUFFIX.items():\n",
    "            dataset_file = dataset_root / f\"{dataset}_{suffix}.csv\"\n",
    "            model_path = dataset_root / \"models\" / f\"ctgan_{dataset}_{encoding}_model.pkl\"\n",
    "            schedule_path = dataset_root / \"training_schedules\" / f\"ctgan_{dataset}_{encoding}_losses.png\"\n",
    "\n",
    "            if not dataset_file.exists() or not model_path.exists():\n",
    "                continue\n",
    "\n",
    "            card = Card(\n",
    "                dataset=dataset,\n",
    "                encoding=encoding,\n",
    "                target=target,\n",
    "                dataset_path=str(dataset_file),\n",
    "                model_path=str(model_path),\n",
    "                schedule_path=str(schedule_path),\n",
    "            )\n",
    "            cards[dataset].append(card)\n",
    "\n",
    "    return cards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cards_to_frame(cards_by_dataset: Dict[str, List[Card]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for dataset, items in cards_by_dataset.items():\n",
    "        for card in items:\n",
    "            rows.append({\n",
    "                \"dataset\": dataset,\n",
    "                \"encoding\": card.encoding,\n",
    "                \"rows\": len(card.real_data),\n",
    "                \"features\": card.real_data.shape[1] - 1,\n",
    "                \"logreg_real\": card.logistic_real_score,\n",
    "                \"logreg_synt\": card.logistic_synt_score,\n",
    "                \"logreg_gap\": card.logistic_real_score - card.logistic_synt_score,\n",
    "                \"xgb_real\": card.xgb_real_score,\n",
    "                \"xgb_synt\": card.xgb_synt_score,\n",
    "                \"xgb_gap\": card.xgb_real_score - card.xgb_synt_score,\n",
    "                \"mean_jsd\": card.mean_jsd,\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def save_cards_summary(cards_by_dataset: Dict[str, List[Card]], output_path: str = \"data.csv\") -> pd.DataFrame:\n",
    "    df = cards_to_frame(cards_by_dataset)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from datetime import datetime\n",
    "from html import escape\n",
    "\n",
    "\n",
    "def _fmt(value: float | int | None, ndigits: int = 3) -> str:\n",
    "    if value is None or (isinstance(value, float) and np.isnan(value)):\n",
    "        return \"—\"\n",
    "    return f\"{value:.{ndigits}f}\" if isinstance(value, float) else str(value)\n",
    "\n",
    "\n",
    "def _encoding_label(name: str) -> str:\n",
    "    return ENCODING_LABELS.get(name, name)\n",
    "\n",
    "\n",
    "def _card_anchor(card: Card) -> str:\n",
    "    return f\"{card.dataset}-{card.encoding}\".replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "def _embed_image_base64(path: str) -> str:\n",
    "    if not path:\n",
    "        return \"\"\n",
    "    img_path = Path(path)\n",
    "    if not img_path.exists():\n",
    "        return \"\"\n",
    "    data = img_path.read_bytes()\n",
    "    mime = {\n",
    "        \"png\": \"image/png\",\n",
    "        \"jpg\": \"image/jpeg\",\n",
    "        \"jpeg\": \"image/jpeg\",\n",
    "        \"gif\": \"image/gif\",\n",
    "        \"svg\": \"image/svg+xml\",\n",
    "    }.get(img_path.suffix.lower().lstrip(\".\"), \"image/png\")\n",
    "    b64 = base64.b64encode(data).decode(\"ascii\")\n",
    "    return f\"<img class='schedule-img' src='data:{mime};base64,{b64}' alt='training schedule'>\"\n",
    "\n",
    "\n",
    "def _render_jsd_table(card: Card, top_k: int = 15) -> str:\n",
    "    if card.jensen_shannon_divergence is None or card.jensen_shannon_divergence.empty:\n",
    "        return \"<div class='meta'>Нет доступных метрик.</div>\"\n",
    "    df = card.jensen_shannon_divergence.sort_values(\"jensen_shannon_divergence\", ascending=False)\n",
    "    if top_k:\n",
    "        df = df.head(top_k)\n",
    "    rows = \"\".join(\n",
    "        f\"<tr><td>{escape(str(r['column']))}</td><td class='right'>{_fmt(r['jensen_shannon_divergence'])}</td></tr>\"\n",
    "        for _, r in df.iterrows()\n",
    "    )\n",
    "    return f\"\"\"\n",
    "    <table class=\"jsd-table\">\n",
    "      <thead>\n",
    "        <tr><th>Колонка</th><th class='right'>JSD</th></tr>\n",
    "      </thead>\n",
    "      <tbody>{rows}</tbody>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def _render_matrix(cards_by_dataset: Dict[str, List[Card]]) -> str:\n",
    "    encodings = sorted({c.encoding for items in cards_by_dataset.values() for c in items})\n",
    "    head = \"\".join(f\"<th>{_encoding_label(e)}</th>\" for e in encodings)\n",
    "    rows_html = []\n",
    "    for dataset, items in cards_by_dataset.items():\n",
    "        row_cells = [f\"<td class='row-title'>{escape(dataset)}</td>\"]\n",
    "        for encoding in encodings:\n",
    "            card = next((c for c in items if c.encoding == encoding), None)\n",
    "            if card is None:\n",
    "                row_cells.append(\"<td class='empty'>—</td>\")\n",
    "                continue\n",
    "            anchor = _card_anchor(card)\n",
    "            cell = f\"\"\"\n",
    "            <a class=\"cell-link\" href=\"#{anchor}\">\n",
    "              <div class=\"cell-card\">\n",
    "                <div class=\"cell-title\">{_encoding_label(encoding)}</div>\n",
    "                <div class=\"cell-body\">LR syn: {_fmt(card.logistic_synt_score)} / {_fmt(card.logistic_real_score)}<br>\n",
    "                XGB syn: {_fmt(card.xgb_synt_score)} / {_fmt(card.xgb_real_score)}<br>\n",
    "                Mean JSD: {_fmt(card.mean_jsd)}</div>\n",
    "              </div>\n",
    "            </a>\n",
    "            \"\"\"\n",
    "            row_cells.append(f\"<td>{cell}</td>\")\n",
    "        rows_html.append(f\"<tr>{''.join(row_cells)}</tr>\")\n",
    "    return f\"\"\"\n",
    "    <table class=\"matrix\">\n",
    "      <thead><tr><th>Датасет</th>{head}</tr></thead>\n",
    "      <tbody>{''.join(rows_html)}</tbody>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def _render_cards(cards_by_dataset: Dict[str, List[Card]], top_k: int = 15) -> str:\n",
    "    cards_html = []\n",
    "    for dataset, items in sorted(cards_by_dataset.items()):\n",
    "        for card in sorted(items, key=lambda c: c.encoding):\n",
    "            anchor = _card_anchor(card)\n",
    "            metrics_list = \"\".join([\n",
    "                f\"<li>LogReg (real): {_fmt(card.logistic_real_score)}</li>\",\n",
    "                f\"<li>LogReg (synthetic): {_fmt(card.logistic_synt_score)}</li>\",\n",
    "                f\"<li>XGBoost (real): {_fmt(card.xgb_real_score)}</li>\",\n",
    "                f\"<li>XGBoost (synthetic): {_fmt(card.xgb_synt_score)}</li>\",\n",
    "                f\"<li>Mean JSD: {_fmt(card.mean_jsd)}</li>\",\n",
    "                f\"<li>Rows: {len(card.real_data)}</li>\",\n",
    "                f\"<li>Features: {card.real_data.shape[1] - 1}</li>\",\n",
    "            ])\n",
    "            cards_html.append(f\"\"\"\n",
    "            <section class=\"card\" id=\"{anchor}\">\n",
    "              <h2>{escape(dataset)} — {_encoding_label(card.encoding)}</h2>\n",
    "              <div class=\"meta\">target: {escape(card.target)}</div>\n",
    "              <ul class=\"metrics\">{metrics_list}</ul>\n",
    "              {_embed_image_base64(card.schedule_path)}\n",
    "              <details open>\n",
    "                <summary>Метрики распределений (JSD) — top {top_k}</summary>\n",
    "                {_render_jsd_table(card, top_k=top_k)}\n",
    "              </details>\n",
    "            </section>\n",
    "            \"\"\")\n",
    "    return \"\".join(cards_html)\n",
    "\n",
    "\n",
    "def render_report(cards_by_dataset: Dict[str, List[Card]], output_path: str = \"report.html\", top_k: int = 15) -> str:\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    style = \"\"\"\n",
    "    <style>\n",
    "      body { font-family: Arial, sans-serif; margin: 0 auto; padding: 24px; max-width: 1200px; background:#f9fafb; color:#1f2933; }\n",
    "      h1 { margin-top: 0; }\n",
    "      table { border-collapse: collapse; width: 100%; }\n",
    "      th, td { border: 1px solid #e5e7eb; padding: 8px 10px; vertical-align: top; }\n",
    "      th { background: #f1f5f9; }\n",
    "      .row-title { font-weight: 700; background: #eef2ff; }\n",
    "      .empty { color: #cbd5e1; text-align: center; }\n",
    "      .cell-link { color: inherit; text-decoration: none; display: block; }\n",
    "      .cell-card { background: #fff; border: 1px solid #e5e7eb; border-radius: 6px; padding: 8px; box-shadow: 0 1px 2px rgba(0,0,0,0.05); transition: transform 0.1s ease; }\n",
    "      .cell-card:hover { transform: translateY(-2px); }\n",
    "      .cell-title { font-weight: 700; margin-bottom: 4px; }\n",
    "      .cell-body { font-size: 13px; line-height: 1.35; }\n",
    "      .card { background: #fff; border: 1px solid #e5e7eb; border-radius: 8px; padding: 16px; margin-bottom: 16px; box-shadow: 0 2px 4px rgba(0,0,0,0.06); }\n",
    "      .metrics { list-style: none; padding-left: 16px; }\n",
    "      .metrics li { margin-bottom: 4px; }\n",
    "      .schedule-img { max-width: 100%; height: auto; margin: 12px 0; display: block; }\n",
    "      details summary { cursor: pointer; font-weight: 700; }\n",
    "      details { margin-top: 8px; }\n",
    "      .meta { color: #475569; margin-bottom: 6px; }\n",
    "      .jsd-table { width: 100%; border-collapse: collapse; }\n",
    "      .jsd-table th, .jsd-table td { border: 1px solid #e5e7eb; padding: 6px 8px; }\n",
    "      .jsd-table th { background: #f8fafc; }\n",
    "      .right { text-align: right; }\n",
    "      .subtitle { color: #475569; margin-bottom: 12px; }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "    matrix = _render_matrix(cards_by_dataset)\n",
    "    cards_html = _render_cards(cards_by_dataset, top_k=top_k)\n",
    "\n",
    "    html = f\"\"\"<!doctype html>\n",
    "    <html lang='ru'>\n",
    "      <meta charset='utf-8'>\n",
    "      <meta name='viewport' content='width=device-width, initial-scale=1'>\n",
    "      <title>Cards report</title>\n",
    "      {style}\n",
    "      <body>\n",
    "        <h1>Сводный отчёт по моделям</h1>\n",
    "        <div class='subtitle'>Сгенерировано: {escape(now)}</div>\n",
    "        <h3>Матрица: датасеты × кодировки</h3>\n",
    "        {matrix}\n",
    "        <h3>Карточки</h3>\n",
    "        {cards_html}\n",
    "      </body>\n",
    "    </html>\"\"\"\n",
    "\n",
    "    Path(output_path).write_text(html, encoding=\"utf-8\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_by_dataset = build_cards_from_registry(\"datasets/datasets_registry.csv\")\n",
    "for items in cards_by_dataset.values():\n",
    "    for card in items:\n",
    "        evaluate_card(card)\n",
    "\n",
    "summary_df = save_cards_summary(cards_by_dataset, output_path=\"data.csv\")\n",
    "render_report(cards_by_dataset, output_path=\"report.html\", top_k=20)\n",
    "summary_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}