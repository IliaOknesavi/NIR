import os
import pandas as pd
import numpy as np
import ssl  # <--- –î–æ–±–∞–≤–ª–µ–Ω–æ

# --- FIX FOR MACOS SSL ERROR ---
# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
ssl._create_default_https_context = ssl._create_unverified_context
# -------------------------------

from sklearn.datasets import fetch_openml, fetch_california_housing

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
OUTPUT_DIR = "datasets"
TARGET_ROWS = 10000
RANDOM_STATE = 42

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
os.makedirs(OUTPUT_DIR, exist_ok=True)


def process_and_save(name, df, target_rows=TARGET_ROWS):
    """
    –û—á–∏—â–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç, —Å–µ–º–ø–ª–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ CSV.
    """
    # 1. –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    initial_rows = len(df)
    df = df.dropna()

    # 2. –°–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ —Å—Ç—Ä–æ–∫ –±–æ–ª—å—à–µ, —á–µ–º –Ω—É–∂–Ω–æ)
    if len(df) > target_rows:
        df = df.sample(n=target_rows, random_state=RANDOM_STATE).reset_index(
            drop=True)
    else:
        print(
            f"‚ö†Ô∏è {name}: —Å—Ç—Ä–æ–∫ –º–µ–Ω—å—à–µ —Ü–µ–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è ({len(df)} < {target_rows})")

    # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    file_path = os.path.join(OUTPUT_DIR, f"{name}.csv")
    df.to_csv(file_path, index=False)

    # –û—Ç—á–µ—Ç
    cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns
    num_cols = df.select_dtypes(include=['number']).columns

    print(f"‚úÖ {name:<20} | Saved: {len(df)} rows | Cols: {df.shape[1]} "
          f"(Num: {len(num_cols)}, Cat: {len(cat_cols)})")


# --- –ì–†–£–ü–ü–ê 1: –ß–ò–°–õ–û–í–´–ï (NUMERICAL) ---

print("\nDownloading Numerical Datasets...")

# 1. Magic Gamma Telescope
# OpenML ID: 1120
data = fetch_openml(data_id=1120, as_frame=True, parser='auto')
df = pd.concat([data.data, data.target], axis=1)
process_and_save("magic_gamma", df)

# 2. California Housing (Sklearn built-in)
california = fetch_california_housing(as_frame=True)
df = pd.concat([california.data, california.target], axis=1)
process_and_save("california_housing", df)

# 3. Letter Recognition
# OpenML ID: 6
data = fetch_openml(data_id=6, as_frame=True, parser='auto')
df = pd.concat([data.data, data.target], axis=1)
process_and_save("letter_recognition", df)

# --- –ì–†–£–ü–ü–ê 2: –°–ú–ï–®–ê–ù–ù–´–ï (MIXED) ---

print("\nDownloading Mixed Datasets...")

# 4. Adult (Census Income)
# OpenML ID: 1590
data = fetch_openml(data_id=1590, as_frame=True, parser='auto')
df = pd.concat([data.data, data.target], axis=1)
# –£–¥–∞–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å (fnlwgt —á–∞—Å—Ç–æ —É–¥–∞–ª—è—é—Ç, –Ω–æ –æ—Å—Ç–∞–≤–∏–º –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã)
process_and_save("adult", df)

# 5. Bank Marketing
# OpenML ID: 1461
data = fetch_openml(data_id=1461, as_frame=True, parser='auto')
df = pd.concat([data.data, data.target], axis=1)
process_and_save("bank_marketing", df)

# 6. Default of Credit Card Clients
# OpenML ID: 42477
data = fetch_openml(data_id=42477, as_frame=True, parser='auto')
df = pd.concat([data.data, data.target], axis=1)
process_and_save("default_credit", df)

# 7. Online Shoppers Purchasing Intention
# –ü—Ä—è–º–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å UCI, —Ç–∞–∫ –∫–∞–∫ –Ω–∞ OpenML –≤–µ—Ä—Å–∏–∏ –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è
url_shoppers = "https://archive.ics.uci.edu/ml/machine-learning-databases/00468/online_shoppers_intention.csv"
try:
    df = pd.read_csv(url_shoppers)
    process_and_save("online_shoppers", df)
except Exception as e:
    print(f"‚ùå Failed to load Online Shoppers: {e}")

# --- –ì–†–£–ü–ü–ê 3: –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–ï (CATEGORICAL) ---

print("\nDownloading Categorical Datasets...")

# 8. Nursery
# OpenML ID: 26
# Rows: ~12960, Cols: 8 (All Categorical)
data = fetch_openml(data_id=26, as_frame=True, parser='auto')
df = pd.concat([data.data, data.target], axis=1)
process_and_save("nursery", df)

# 9. Connect-4 (–ó–∞–º–µ–Ω–∞ –¥–ª—è Chess)
# OpenML ID: 40668
# Rows: ~67557, Cols: 42 (All Categorical)
# –≠—Ç–æ –æ—Ç–ª–∏—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: –ø–æ–ª–Ω–æ—Å—Ç—å—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –∏ –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π
try:
    data = fetch_openml(data_id=40668, as_frame=True, parser='auto')
    df = pd.concat([data.data, data.target], axis=1)
    process_and_save("connect_4", df)
except Exception as e:
    print(f"‚ùå Failed to load Connect-4: {e}")

# 10. Phishing Websites
# OpenML ID: 4534
# Rows: ~11055, Cols: 30 (All Categorical features encoded as -1, 0, 1)
try:
    data = fetch_openml(data_id=4534, as_frame=True, parser='auto')
    df = pd.concat([data.data, data.target], axis=1)
    process_and_save("phishing_websites", df)
except Exception as e:
    print(
        f"‚ùå Failed to load Phishing Websites via OpenML. Trying fallback URL...")
    # –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ UCI –≤–µ—Ä—Å–∏—é, –µ—Å–ª–∏ OpenML –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    url_phish = "https://archive.ics.uci.edu/ml/machine-learning-databases/00327/Training%20Dataset.arff"
    from scipy.io import arff
    import urllib.request
    import io

    # –°–∫–∞—á–∏–≤–∞–µ–º –∏ —á–∏—Ç–∞–µ–º ARFF
    resp = urllib.request.urlopen(url_phish)
    data, meta = arff.loadarff(io.StringIO(resp.read().decode('utf-8')))
    df = pd.DataFrame(data)
    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –±–∞–π—Ç–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –æ–±—ã—á–Ω—ã–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    for col in df.columns:
        if df[col].dtype == object:
            df[col] = df[col].str.decode('utf-8')
    process_and_save("phishing_websites", df)

print("\nüéâ –ì–æ—Ç–æ–≤–æ! –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ 'datasets/'.")
