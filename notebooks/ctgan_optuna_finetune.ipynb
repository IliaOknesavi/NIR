{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTGAN finetuning с Optuna\n",
    "\n",
    "Нотбук подбирает гиперпараметры CTGAN для выбранного датасета и метода кодирования из реестра. В качестве целевой метрики используется качество модели, обученной на синтетике и проверенной на реальных данных (accuracy или R²). Лучшие параметры сохраняются в файл `<dataset_name>.txt` в папке `optuna_results`."
   ],
   "id": "35122fd4993c3f18"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T10:04:59.858578Z",
     "start_time": "2025-12-10T10:04:59.852230Z"
    }
   },
   "source": [
    "import ast\n",
    "import json\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ctgan import CTGAN\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Конфигурация для полного запуска\n",
    "CANDIDATE_REGISTRY_PATHS = [\n",
    "    Path(\"datasets/datasets_registry.csv\"),\n",
    "    Path(\"../datasets/datasets_registry.csv\"),\n",
    "    Path(\"datasets_registry.csv\"),\n",
    "    Path(\"../datasets_registry.csv\"),\n",
    "]\n",
    "DATASETS_REGISTRY = next((p for p in CANDIDATE_REGISTRY_PATHS if p.exists()), CANDIDATE_REGISTRY_PATHS[0])\n",
    "dataset_name = \"adult\"                # имя датасета из реестра\n",
    "encoding_method = \"one_hot_encoding\"  # one_hot_encoding | label_encoding | frequency_encoding | original\n",
    "N_TRIALS = 120                         # количество попыток Optuna для полного поиска\n",
    "EPOCHS = 300                           # количество эпох обучения CTGAN на каждую попытку\n",
    "RANDOM_STATE = 42\n",
    "OUTPUT_DIR = Path(\"optuna_results\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "output_path = OUTPUT_DIR / f\"{dataset_name}.txt\"\n"
   ],
   "id": "eb82553301381446",
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T10:04:59.872116Z",
     "start_time": "2025-12-10T10:04:59.864678Z"
    }
   },
   "source": [
    "def load_registry(registry_path: Path = DATASETS_REGISTRY) -> pd.DataFrame:\n",
    "    if not registry_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Не найден datasets_registry.csv. Проверьте пути: {[str(p) for p in CANDIDATE_REGISTRY_PATHS]}\"\n",
    "        )\n",
    "    df = pd.read_csv(registry_path, skipinitialspace=True)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    df[\"dataset_name\"] = df[\"dataset_name\"].str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def _resolve_path(path_str: str, anchors: list[Path]) -> Path:\n",
    "    p = Path(path_str)\n",
    "    if p.is_absolute():\n",
    "        return p\n",
    "\n",
    "    # Если путь начинается с datasets/, пробуем от корня репозитория\n",
    "    if path_str.startswith(\"datasets/\"):\n",
    "        for anchor in anchors:\n",
    "            candidate = (anchor / path_str).resolve()\n",
    "            if candidate.exists():\n",
    "                return candidate\n",
    "\n",
    "    for anchor in anchors:\n",
    "        candidate = (anchor / path_str).resolve()\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "\n",
    "    return (anchors[0] / path_str).resolve()\n",
    "\n",
    "\n",
    "def get_dataset_info(name: str) -> dict:\n",
    "    registry = load_registry()\n",
    "    row = registry.loc[registry[\"dataset_name\"] == name]\n",
    "    if row.empty:\n",
    "        raise ValueError(f\"Датасет {name} не найден в {DATASETS_REGISTRY}\")\n",
    "    rec = row.iloc[0]\n",
    "\n",
    "    repo_root = DATASETS_REGISTRY.parent.parent.resolve()\n",
    "    anchors = [repo_root, DATASETS_REGISTRY.parent.resolve(), Path.cwd()]\n",
    "\n",
    "    dataset_csv = _resolve_path(str(rec[\"dataset_csv\"]), anchors)\n",
    "    dataset_path = _resolve_path(str(rec[\"dataset_path\"]), anchors)\n",
    "\n",
    "    return {\n",
    "        \"dataset_csv\": dataset_csv,\n",
    "        \"dataset_path\": dataset_path,\n",
    "        \"target\": rec[\"target\"].strip(),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_encoded_dataset(name: str, method: str):\n",
    "    info = get_dataset_info(name)\n",
    "    data_csv_path = info[\"dataset_csv\"]\n",
    "    if not data_csv_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"{data_csv_path} не найден. Выполните notebooks/dataset_encoding.ipynb или скорректируйте путь в datasets_registry.csv\"\n",
    "        )\n",
    "\n",
    "    data_df = pd.read_csv(data_csv_path)\n",
    "    row = data_df.loc[data_df[\"method\"] == method]\n",
    "    if row.empty:\n",
    "        raise ValueError(f\"Метод {method} не найден в {data_csv_path}\")\n",
    "\n",
    "    rec = row.iloc[0]\n",
    "    new_cat_cols_raw = str(rec.get(\"New_cat_cols\", \"[]\"))\n",
    "    try:\n",
    "        new_cat_cols = ast.literal_eval(new_cat_cols_raw)\n",
    "    except Exception:\n",
    "        new_cat_cols = []\n",
    "\n",
    "    repo_root = DATASETS_REGISTRY.parent.parent.resolve()\n",
    "    anchors = [repo_root, DATASETS_REGISTRY.parent.resolve(), data_csv_path.parent.resolve(), Path.cwd()]\n",
    "    dataset_path = _resolve_path(str(rec[\"path\"]), anchors)\n",
    "\n",
    "    if not dataset_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"{dataset_path} не найден. Перегенерируйте кодировки через dataset_encoding.ipynb\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"csv_path\": dataset_path,\n",
    "        \"target\": info[\"target\"],\n",
    "        \"discrete_features\": [c for c in new_cat_cols if c],\n",
    "    }\n",
    "\n"
   ],
   "id": "dd9103cc7cf9238e",
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T10:04:59.922525Z",
     "start_time": "2025-12-10T10:04:59.877727Z"
    }
   },
   "source": [
    "def prepare_data(csv_path: Path, target: str):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Целевая колонка {target} отсутствует в {csv_path}\")\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    is_regression = y.nunique() > 20 and pd.api.types.is_numeric_dtype(y)\n",
    "    return df, X, y, is_regression\n",
    "\n",
    "\n",
    "def evaluate_synthetic_quality(df_real: pd.DataFrame, df_synth: pd.DataFrame, target: str, is_regression: bool):\n",
    "    X_real = df_real.drop(columns=[target])\n",
    "    y_real = df_real[target]\n",
    "    X_synth = df_synth.drop(columns=[target])\n",
    "    y_synth = df_synth[target]\n",
    "\n",
    "    X_train_syn, _, y_train_syn, _ = train_test_split(\n",
    "        X_synth, y_synth, test_size=0.25, random_state=RANDOM_STATE, stratify=None\n",
    "    )\n",
    "    X_train_real, X_val_real, y_train_real, y_val_real = train_test_split(\n",
    "        X_real, y_real, test_size=0.25, random_state=RANDOM_STATE, stratify=None\n",
    "    )\n",
    "\n",
    "    if is_regression:\n",
    "        model = make_pipeline(StandardScaler(), Ridge(random_state=RANDOM_STATE))\n",
    "        model.fit(X_train_syn, y_train_syn)\n",
    "        preds = model.predict(X_val_real)\n",
    "        return r2_score(y_val_real, preds)\n",
    "\n",
    "    # Классификация\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(max_iter=2000, solver=\"lbfgs\", n_jobs=4),\n",
    "    )\n",
    "    model.fit(X_train_syn, y_train_syn)\n",
    "    preds = model.predict(X_val_real)\n",
    "    return accuracy_score(y_val_real, preds)\n",
    "\n",
    "\n",
    "def objective(trial, df_real, target, discrete_features, is_regression):\n",
    "    params = {\n",
    "        \"embedding_dim\": trial.suggest_int(\"embedding_dim\", 64, 256, step=32),\n",
    "        \"gen_dim\": trial.suggest_categorical(\"gen_dim\", [128, 256, 512]),\n",
    "        \"disc_dim\": trial.suggest_categorical(\"disc_dim\", [64, 128, 256]),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [256, 512, 1024]),\n",
    "        \"generator_lr\": trial.suggest_float(\"generator_lr\", 1e-4, 5e-3, log=True),\n",
    "        \"discriminator_lr\": trial.suggest_float(\"discriminator_lr\", 1e-4, 5e-3, log=True),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        ctgan = CTGAN(\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=int(params[\"batch_size\"]),\n",
    "            embedding_dim=int(params[\"embedding_dim\"]),\n",
    "            generator_dim=(int(params[\"gen_dim\"]), int(params[\"gen_dim\"])),\n",
    "            discriminator_dim=(int(params[\"disc_dim\"]), int(params[\"disc_dim\"])),\n",
    "            generator_lr=params[\"generator_lr\"],\n",
    "            discriminator_lr=params[\"discriminator_lr\"],\n",
    "            pac=1,\n",
    "            enable_gpu=False,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        ctgan.fit(df_real, discrete_features)\n",
    "        df_synth = ctgan.sample(len(df_real))\n",
    "\n",
    "        score = evaluate_synthetic_quality(df_real, df_synth, target, is_regression)\n",
    "        return score\n",
    "    except Exception:\n",
    "        print(\"Trial failed:\")\n",
    "        traceback.print_exc()\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "encoded_info = get_encoded_dataset(dataset_name, encoding_method)\n",
    "df_real, X_real, y_real, is_regression = prepare_data(encoded_info[\"csv_path\"], encoded_info[\"target\"])\n",
    "discrete_features = [c for c in encoded_info[\"discrete_features\"] if c in df_real.columns]\n",
    "print(f\"Датасет: {dataset_name} | метод: {encoding_method} | строк: {len(df_real)} | фичей: {X_real.shape[1]} | дискретных: {len(discrete_features)}\")\n",
    "\n"
   ],
   "id": "5f4adb179eed1ec5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет: adult | метод: one_hot_encoding | строк: 10000 | фичей: 118 | дискретных: 113\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-10T10:04:59.928119Z"
    }
   },
   "source": [
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=0)\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=f\"ctgan_{dataset_name}_{encoding_method}\",\n",
    "    pruner=pruner,\n",
    ")\n",
    "study.optimize(\n",
    "    lambda trial: objective(trial, df_real, encoded_info[\"target\"], discrete_features, is_regression),\n",
    "    n_trials=N_TRIALS,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "print(\"Лучший результат:\", study.best_value)\n",
    "print(\"Параметры:\")\n",
    "print(json.dumps(study.best_trial.params, indent=2))\n",
    "\n",
    "result_payload = {\n",
    "    \"dataset\": dataset_name,\n",
    "    \"method\": encoding_method,\n",
    "    \"score\": study.best_value,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"n_trials\": N_TRIALS,\n",
    "    \"params\": study.best_trial.params,\n",
    "}\n",
    "\n",
    "output_path.write_text(json.dumps(result_payload, indent=2), encoding=\"utf-8\")\n",
    "print(f\"Сохранено: {output_path.resolve()}\")\n",
    "\n"
   ],
   "id": "e916daae8de2f54e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-10 13:04:59,929] A new study created in memory with name: ctgan_adult_one_hot_encoding\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
