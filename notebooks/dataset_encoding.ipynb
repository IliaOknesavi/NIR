{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка датасетов с различными методами кодирования\n",
    "Этот ноутбук обрабатывает датасеты из `datasets/original/` используя три метода кодирования:\n",
    "- One-Hot Encoding\n",
    "- Label Encoding\n",
    "- Frequency Encoding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:44.602342Z",
     "start_time": "2025-12-04T05:47:44.590909Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import os\n",
    "import ast\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка реестра датасетов"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:44.616343Z",
     "start_time": "2025-12-04T05:47:44.612500Z"
    }
   },
   "source": [
    "def load_datasets_registry(registry_path='../datasets/datasets_registry.csv'):\n",
    "    \"\"\"\n",
    "    Загружает реестр датасетов и преобразует его в список структур.\n",
    "\n",
    "    Args:\n",
    "        registry_path: путь к файлу datasets_registry.csv\n",
    "\n",
    "    Returns:\n",
    "        list: список словарей с информацией о датасетах\n",
    "    \"\"\"\n",
    "    # Читаем CSV с учетом многострочных значений\n",
    "    df = pd.read_csv(registry_path, skipinitialspace=True)\n",
    "\n",
    "    datasets_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Проверяем, является ли значение в cat_col пустым (NaN)\n",
    "        if pd.isna(row['cat_col']):\n",
    "            cat_cols_list = []\n",
    "        else:\n",
    "            # Обрабатываем cat_col - он может быть многострочным\n",
    "            cat_col_str = str(row['cat_col']).replace('\\n', '').replace('\\r', '').strip()\n",
    "            try:\n",
    "                # Проверяем, не пустая ли строка после очистки\n",
    "                if cat_col_str:\n",
    "                    cat_cols_list = ast.literal_eval(cat_col_str)\n",
    "                else:\n",
    "                    cat_cols_list = []\n",
    "            except (ValueError, SyntaxError):\n",
    "                # Если строка все равно не парсится, считаем ее пустой\n",
    "                cat_cols_list = []\n",
    "\n",
    "        dataset_info = {\n",
    "            'dataset_name': row['dataset_name'].strip(),\n",
    "            'dataset_path': row['dataset_path'].strip(),\n",
    "            'dataset_csv': row['dataset_csv'].strip(),\n",
    "            'target': row['target'].strip(),\n",
    "            'cat_cols': cat_cols_list\n",
    "        }\n",
    "        datasets_list.append(dataset_info)\n",
    "\n",
    "    return datasets_list\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:44.653452Z",
     "start_time": "2025-12-04T05:47:44.634283Z"
    }
   },
   "source": [
    "# Загружаем реестр датасетов\n",
    "# Указываем корректный путь к файлу относительно расположения ноутбука\n",
    "datasets = load_datasets_registry(registry_path='../datasets/datasets_registry.csv')\n",
    "print(f\"Загружено {len(datasets)} датасет(ов)\")\n",
    "print(\"\\nПример структуры:\")\n",
    "print(datasets[0])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 11 датасет(ов)\n",
      "\n",
      "Пример структуры:\n",
      "{'dataset_name': 'adult', 'dataset_path': 'datasets/original/adult.csv', 'dataset_csv': 'datasets/adult/data.csv', 'target': 'class', 'cat_cols': ['workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Функция One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:44.683281Z",
     "start_time": "2025-12-04T05:47:44.670111Z"
    }
   },
   "source": [
    "def ohe_encoding(datasets_list):\n",
    "    \"\"\"\n",
    "    Применяет One-Hot Encoding к категориальным признакам датасетов.\n",
    "    Сохраняет результат в папку датасета и добавляет запись в data.csv.\n",
    "\n",
    "    Args:\n",
    "        datasets_list: список словарей с информацией о датасетах\n",
    "    \"\"\"\n",
    "    for dataset_info in datasets_list:\n",
    "        try:\n",
    "            print(f\"\\nОбработка {dataset_info['dataset_name']} - One-Hot Encoding...\")\n",
    "\n",
    "            # Загружаем датасет, корректируя путь\n",
    "            original_path = Path(dataset_info['dataset_path'])\n",
    "            df = pd.read_csv(Path('..') / original_path)\n",
    "            print(f\"  Загружено {len(df)} строк, {len(df.columns)} колонок\")\n",
    "\n",
    "            # Получаем категориальные колонки (исключая target, если он в списке)\n",
    "            cat_cols = [col for col in dataset_info['cat_cols'] if col in df.columns]\n",
    "            target = dataset_info['target']\n",
    "\n",
    "            # Удаляем target из cat_cols если он там есть\n",
    "            cat_cols_to_encode = [col for col in cat_cols if col != target]\n",
    "\n",
    "            # Проверяем, есть ли категориальные признаки кроме target\n",
    "            if len(cat_cols_to_encode) == 0:\n",
    "                print(f\"  Пропущен: нет категориальных признаков кроме target\")\n",
    "                continue\n",
    "\n",
    "            # Применяем One-Hot Encoding с типом int\n",
    "            df_encoded = pd.get_dummies(df, columns=cat_cols_to_encode, prefix_sep='_', drop_first=False, dtype=int)\n",
    "\n",
    "            # Всегда применяем Label Encoding к целевой колонке\n",
    "            if target in df_encoded.columns:\n",
    "                le = LabelEncoder()\n",
    "                df_encoded[target] = le.fit_transform(df_encoded[target].astype(str))\n",
    "\n",
    "            # Получаем список новых категориальных колонок\n",
    "            new_cat_cols = [col for col in df_encoded.columns if col not in df.columns or col in cat_cols_to_encode]\n",
    "            # Добавляем target к новым колонкам если он категориальный\n",
    "            if target in dataset_info['cat_cols']:\n",
    "                new_cat_cols.append(target)\n",
    "\n",
    "            # Создаем папку для датасета, корректируя путь\n",
    "            dataset_folder = Path('..') / Path(dataset_info['dataset_csv']).parent\n",
    "            dataset_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Сохраняем закодированный датасет\n",
    "            output_path = dataset_folder / f\"{dataset_info['dataset_name']}_ohe.csv\"\n",
    "            df_encoded.to_csv(output_path, index=False)\n",
    "            print(f\"  Сохранено в {output_path}\")\n",
    "            print(f\"  Новый размер: {len(df_encoded)} строк, {len(df_encoded.columns)} колонок\")\n",
    "\n",
    "            # Обновляем запись в data.csv\n",
    "            data_csv_path = Path('..') / dataset_info['dataset_csv']\n",
    "            method_name = 'one_hot_encoding'\n",
    "\n",
    "            if os.path.exists(data_csv_path):\n",
    "                data_df = pd.read_csv(data_csv_path)\n",
    "                # Удаляем старую запись для этого метода, если она существует\n",
    "                data_df = data_df[data_df['method'] != method_name]\n",
    "            else:\n",
    "                data_df = pd.DataFrame(columns=['method', 'path', 'New_cat_cols', 'model_path', 'schedul_path',\n",
    "                                                 'JS divergence', 'Utility_XGBoost', 'Utility_logistic_r', 'matrix_distance'])\n",
    "\n",
    "            # Добавляем новую запись\n",
    "            new_row = {\n",
    "                'method': method_name,\n",
    "                'path': str(output_path.relative_to(Path('..'))), # Сохраняем относительный путь\n",
    "                'New_cat_cols': str(new_cat_cols),\n",
    "                'model_path': '',\n",
    "                'schedul_path': '',\n",
    "                'JS divergence': '',\n",
    "                'Utility_XGBoost': '',\n",
    "                'Utility_logistic_r': '',\n",
    "                'matrix_distance': ''\n",
    "            }\n",
    "            data_df = pd.concat([data_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            data_df.to_csv(data_csv_path, index=False)\n",
    "            print(f\"  Запись для '{method_name}' обновлена в {data_csv_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Ошибка при обработке {dataset_info['dataset_name']}: {e}\")\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Функция Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:44.698767Z",
     "start_time": "2025-12-04T05:47:44.692684Z"
    }
   },
   "source": [
    "def label_encoding(datasets_list):\n",
    "    \"\"\"\n",
    "    Применяет Label Encoding к категориальным признакам датасетов.\n",
    "    Сохраняет результат в папку датасета и добавляет запись в data.csv.\n",
    "\n",
    "    Args:\n",
    "        datasets_list: список словарей с информацией о датасетах\n",
    "    \"\"\"\n",
    "    for dataset_info in datasets_list:\n",
    "        try:\n",
    "            print(f\"\\nОбработка {dataset_info['dataset_name']} - Label Encoding...\")\n",
    "\n",
    "            # Загружаем датасет, корректируя путь\n",
    "            original_path = Path(dataset_info['dataset_path'])\n",
    "            df = pd.read_csv(Path('..') / original_path)\n",
    "            print(f\"  Загружено {len(df)} строк, {len(df.columns)} колонок\")\n",
    "\n",
    "            # Получаем категориальные колонки\n",
    "            cat_cols = [col for col in dataset_info['cat_cols'] if col in df.columns]\n",
    "            target = dataset_info['target']\n",
    "\n",
    "            # Проверяем, есть ли категориальные признаки кроме target\n",
    "            cat_cols_without_target = [col for col in cat_cols if col != target]\n",
    "            if len(cat_cols_without_target) == 0:\n",
    "                print(f\"  Пропущен: нет категориальных признаков кроме target\")\n",
    "                continue\n",
    "\n",
    "            # Применяем Label Encoding\n",
    "            df_encoded = df.copy()\n",
    "            encoded_cols = []\n",
    "\n",
    "            for col in cat_cols:\n",
    "                le = LabelEncoder()\n",
    "                df_encoded[col] = le.fit_transform(df[col].astype(str))\n",
    "                encoded_cols.append(col)\n",
    "\n",
    "            # Всегда применяем Label Encoding к целевой колонке (если она еще не была обработана)\n",
    "            if target in df_encoded.columns and target not in encoded_cols:\n",
    "                le = LabelEncoder()\n",
    "                df_encoded[target] = le.fit_transform(df_encoded[target].astype(str))\n",
    "                encoded_cols.append(target)\n",
    "\n",
    "            # Формируем список новых категориальных колонок (все закодированные колонки)\n",
    "            new_cat_cols = encoded_cols\n",
    "\n",
    "            # Создаем папку для датасета, корректируя путь\n",
    "            dataset_folder = Path('..') / Path(dataset_info['dataset_csv']).parent\n",
    "            dataset_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Сохраняем закодированный датасет\n",
    "            output_path = dataset_folder / f\"{dataset_info['dataset_name']}_label.csv\"\n",
    "            df_encoded.to_csv(output_path, index=False)\n",
    "            print(f\"  Сохранено в {output_path}\")\n",
    "            print(f\"  Размер: {len(df_encoded)} строк, {len(df_encoded.columns)} колонок\")\n",
    "            print(f\"  Закодированные колонки: {new_cat_cols}\")\n",
    "\n",
    "            # Обновляем запись в data.csv\n",
    "            data_csv_path = Path('..') / dataset_info['dataset_csv']\n",
    "            method_name = 'label_encoding'\n",
    "\n",
    "            if os.path.exists(data_csv_path):\n",
    "                data_df = pd.read_csv(data_csv_path)\n",
    "                # Удаляем старую запись для этого метода, если она существует\n",
    "                data_df = data_df[data_df['method'] != method_name]\n",
    "            else:\n",
    "                data_df = pd.DataFrame(columns=['method', 'path', 'New_cat_cols', 'model_path', 'schedul_path',\n",
    "                                                 'JS divergence', 'Utility_XGBoost', 'Utility_logistic_r', 'matrix_distance'])\n",
    "\n",
    "            # Добавляем новую запись\n",
    "            new_row = {\n",
    "                'method': method_name,\n",
    "                'path': str(output_path.relative_to(Path('..'))), # Сохраняем относительный путь\n",
    "                'New_cat_cols': str(new_cat_cols),\n",
    "                'model_path': '',\n",
    "                'schedul_path': '',\n",
    "                'JS divergence': '',\n",
    "                'Utility_XGBoost': '',\n",
    "                'Utility_logistic_r': '',\n",
    "                'matrix_distance': ''\n",
    "            }\n",
    "            data_df = pd.concat([data_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            data_df.to_csv(data_csv_path, index=False)\n",
    "            print(f\"  Запись для '{method_name}' обновлена в {data_csv_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Ошибка при обработке {dataset_info['dataset_name']}: {e}\")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Функция Frequency Encoding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:44.716559Z",
     "start_time": "2025-12-04T05:47:44.709510Z"
    }
   },
   "source": [
    "def frequency_encoding(datasets_list):\n",
    "    \"\"\"\n",
    "    Применяет Frequency Encoding к категориальным признакам датасетов.\n",
    "    Сохраняет результат в папку датасета и добавляет запись в data.csv.\n",
    "\n",
    "    Args:\n",
    "        datasets_list: список словарей с информацией о датасетах\n",
    "    \"\"\"\n",
    "    for dataset_info in datasets_list:\n",
    "        try:\n",
    "            print(f\"\\nОбработка {dataset_info['dataset_name']} - Frequency Encoding...\")\n",
    "\n",
    "            # Загружаем датасет, корректируя путь\n",
    "            original_path = Path(dataset_info['dataset_path'])\n",
    "            df = pd.read_csv(Path('..') / original_path)\n",
    "            print(f\"  Загружено {len(df)} строк, {len(df.columns)} колонок\")\n",
    "\n",
    "            # Получаем категориальные колонки\n",
    "            cat_cols = [col for col in dataset_info['cat_cols'] if col in df.columns]\n",
    "            target = dataset_info['target']\n",
    "\n",
    "            # Проверяем, есть ли категориальные признаки кроме target\n",
    "            cat_cols_without_target = [col for col in cat_cols if col != target]\n",
    "            if len(cat_cols_without_target) == 0:\n",
    "                print(f\"  Пропущен: нет категориальных признаков кроме target\")\n",
    "                continue\n",
    "\n",
    "            # Применяем Frequency Encoding (но не к target)\n",
    "            df_encoded = df.copy()\n",
    "            encoded_cols = []\n",
    "\n",
    "            for col in cat_cols:\n",
    "                # Пропускаем target, он будет обработан отдельно через LabelEncoder\n",
    "                if col == target:\n",
    "                    continue\n",
    "                # Вычисляем частоты\n",
    "                freq_map = df[col].value_counts(normalize=True).to_dict()\n",
    "                # Заменяем значения на частоты\n",
    "                df_encoded[col] = df[col].map(freq_map)\n",
    "                encoded_cols.append(col)\n",
    "\n",
    "            # Всегда применяем Label Encoding к целевой колонке\n",
    "            if target in df_encoded.columns:\n",
    "                le = LabelEncoder()\n",
    "                df_encoded[target] = le.fit_transform(df_encoded[target].astype(str))\n",
    "                encoded_cols.append(target)\n",
    "\n",
    "            # Формируем список новых категориальных колонок (все закодированные колонки)\n",
    "            new_cat_cols = encoded_cols\n",
    "\n",
    "            # Создаем папку для датасета, корректируя путь\n",
    "            dataset_folder = Path('..') / Path(dataset_info['dataset_csv']).parent\n",
    "            dataset_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Сохраняем закодированный датасет\n",
    "            output_path = dataset_folder / f\"{dataset_info['dataset_name']}_frequency.csv\"\n",
    "            df_encoded.to_csv(output_path, index=False)\n",
    "            print(f\"  Сохранено в {output_path}\")\n",
    "            print(f\"  Размер: {len(df_encoded)} строк, {len(df_encoded.columns)} колонок\")\n",
    "            print(f\"  Закодированные колонки: {new_cat_cols}\")\n",
    "\n",
    "            # Обновляем запись в data.csv\n",
    "            data_csv_path = Path('..') / dataset_info['dataset_csv']\n",
    "            method_name = 'frequency_encoding'\n",
    "\n",
    "            if os.path.exists(data_csv_path):\n",
    "                data_df = pd.read_csv(data_csv_path)\n",
    "                # Удаляем старую запись для этого метода, если она существует\n",
    "                data_df = data_df[data_df['method'] != method_name]\n",
    "            else:\n",
    "                data_df = pd.DataFrame(columns=['method', 'path', 'New_cat_cols', 'model_path', 'schedul_path',\n",
    "                                                 'JS divergence', 'Utility_XGBoost', 'Utility_logistic_r', 'matrix_distance'])\n",
    "\n",
    "            # Добавляем новую запись\n",
    "            new_row = {\n",
    "                'method': method_name,\n",
    "                'path': str(output_path.relative_to(Path('..'))), # Сохраняем относительный путь\n",
    "                'New_cat_cols': str(new_cat_cols),\n",
    "                'model_path': '',\n",
    "                'schedul_path': '',\n",
    "                'JS divergence': '',\n",
    "                'Utility_XGBoost': '',\n",
    "                'Utility_logistic_r': '',\n",
    "                'matrix_distance': ''\n",
    "            }\n",
    "            data_df = pd.concat([data_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            data_df.to_csv(data_csv_path, index=False)\n",
    "            print(f\"  Запись для '{method_name}' обновлена в {data_csv_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Ошибка при обработке {dataset_info['dataset_name']}: {e}\")"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Функция Original (без кодирования, только target)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:44.740616Z",
     "start_time": "2025-12-04T05:47:44.735671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def original_encoding(datasets_list):\n",
    "    \"\"\"\n",
    "    Сохраняет оригинальный датасет с Label Encoding только для целевой колонки.\n",
    "    Все остальные колонки остаются без изменений.\n",
    "\n",
    "    Args:\n",
    "        datasets_list: список словарей с информацией о датасетах\n",
    "    \"\"\"\n",
    "    for dataset_info in datasets_list:\n",
    "        try:\n",
    "            print(f\"\\nОбработка {dataset_info['dataset_name']} - Original (только target закодирован)...\")\n",
    "\n",
    "            # Загружаем датасет, корректируя путь\n",
    "            original_path = Path(dataset_info['dataset_path'])\n",
    "            df = pd.read_csv(Path('..') / original_path)\n",
    "            print(f\"  Загружено {len(df)} строк, {len(df.columns)} колонок\")\n",
    "\n",
    "            target = dataset_info['target']\n",
    "\n",
    "            # Копируем датасет без изменений\n",
    "            df_encoded = df.copy()\n",
    "\n",
    "            # Применяем Label Encoding только к целевой колонке\n",
    "            if target in df_encoded.columns:\n",
    "                le = LabelEncoder()\n",
    "                df_encoded[target] = le.fit_transform(df_encoded[target].astype(str))\n",
    "                print(f\"  Целевая колонка '{target}' закодирована с помощью LabelEncoder\")\n",
    "\n",
    "            # Список категориальных колонок - только target (если он был категориальным)\n",
    "            new_cat_cols = [target] if target in dataset_info['cat_cols'] and target in df_encoded.columns else []\n",
    "\n",
    "            # Создаем папку для датасета, корректируя путь\n",
    "            dataset_folder = Path('..') / Path(dataset_info['dataset_csv']).parent\n",
    "            dataset_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Сохраняем датасет\n",
    "            output_path = dataset_folder / f\"{dataset_info['dataset_name']}_original.csv\"\n",
    "            df_encoded.to_csv(output_path, index=False)\n",
    "            print(f\"  Сохранено в {output_path}\")\n",
    "            print(f\"  Размер: {len(df_encoded)} строк, {len(df_encoded.columns)} колонок\")\n",
    "            print(f\"  Закодированные колонки: {new_cat_cols}\")\n",
    "\n",
    "            # Обновляем запись в data.csv\n",
    "            data_csv_path = Path('..') / dataset_info['dataset_csv']\n",
    "            method_name = 'original'\n",
    "\n",
    "            if os.path.exists(data_csv_path):\n",
    "                data_df = pd.read_csv(data_csv_path)\n",
    "                # Удаляем старую запись для этого метода, если она существует\n",
    "                data_df = data_df[data_df['method'] != method_name]\n",
    "            else:\n",
    "                data_df = pd.DataFrame(columns=['method', 'path', 'New_cat_cols', 'model_path', 'schedul_path',\n",
    "                                                 'JS divergence', 'Utility_XGBoost', 'Utility_logistic_r', 'matrix_distance'])\n",
    "\n",
    "            # Добавляем новую запись\n",
    "            new_row = {\n",
    "                'method': method_name,\n",
    "                'path': str(output_path.relative_to(Path('..'))), # Сохраняем относительный путь\n",
    "                'New_cat_cols': str(new_cat_cols),\n",
    "                'model_path': '',\n",
    "                'schedul_path': '',\n",
    "                'JS divergence': '',\n",
    "                'Utility_XGBoost': '',\n",
    "                'Utility_logistic_r': '',\n",
    "                'matrix_distance': ''\n",
    "            }\n",
    "            data_df = pd.concat([data_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            data_df.to_csv(data_csv_path, index=False)\n",
    "            print(f\"  Запись для '{method_name}' обновлена в {data_csv_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Ошибка при обработке {dataset_info['dataset_name']}: {e}\")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Запуск обработки датасетов"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:46.687794Z",
     "start_time": "2025-12-04T05:47:44.749952Z"
    }
   },
   "source": [
    "# Применяем One-Hot Encoding\n",
    "print(\"=\"*50)\n",
    "print(\"ONE-HOT ENCODING\")\n",
    "print(\"=\"*50)\n",
    "ohe_encoding(datasets)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ONE-HOT ENCODING\n",
      "==================================================\n",
      "\n",
      "Обработка adult - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 15 колонок\n",
      "  Сохранено в ../datasets/adult/adult_ohe.csv\n",
      "  Новый размер: 10000 строк, 119 колонок\n",
      "  Запись для 'one_hot_encoding' обновлена в ../datasets/adult/data.csv\n",
      "\n",
      "Обработка bank_marketing - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 17 колонок\n",
      "  Сохранено в ../datasets/bank_marketing/bank_marketing_ohe.csv\n",
      "  Новый размер: 10000 строк, 149 колонок\n",
      "  Запись для 'one_hot_encoding' обновлена в ../datasets/bank_marketing/data.csv\n",
      "\n",
      "Обработка california_housing - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 9 колонок\n",
      "  Пропущен: нет категориальных признаков кроме target\n",
      "\n",
      "Обработка chess_kr_k - One-Hot Encoding...\n",
      "  Загружено 1473 строк, 10 колонок\n",
      "  Сохранено в ../datasets/chess_kr_k/chess_kr_k_ohe.csv\n",
      "  Новый размер: 1473 строк, 72 колонок\n",
      "  Запись для 'one_hot_encoding' обновлена в ../datasets/chess_kr_k/data.csv\n",
      "\n",
      "Обработка connect_4 - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 43 колонок\n",
      "  Сохранено в ../datasets/connect_4/connect_4_ohe.csv\n",
      "  Новый размер: 10000 строк, 127 колонок\n",
      "  Запись для 'one_hot_encoding' обновлена в ../datasets/connect_4/data.csv\n",
      "\n",
      "Обработка default_credit - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 24 колонок\n",
      "  Сохранено в ../datasets/default_credit/default_credit_ohe.csv\n",
      "  Новый размер: 10000 строк, 88 колонок\n",
      "  Запись для 'one_hot_encoding' обновлена в ../datasets/default_credit/data.csv\n",
      "\n",
      "Обработка letter_recognition - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 17 колонок\n",
      "  Сохранено в ../datasets/letter_recognition/letter_recognition_ohe.csv\n",
      "  Новый размер: 10000 строк, 256 колонок\n",
      "  Запись для 'one_hot_encoding' обновлена в ../datasets/letter_recognition/data.csv\n",
      "\n",
      "Обработка magic_gamma - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 11 колонок\n",
      "  Пропущен: нет категориальных признаков кроме target\n",
      "\n",
      "Обработка nursery - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 9 колонок\n",
      "  Сохранено в ../datasets/nursery/nursery_ohe.csv\n",
      "  Новый размер: 10000 строк, 28 колонок\n",
      "  Запись для 'one_hot_encoding' обновлена в ../datasets/nursery/data.csv\n",
      "\n",
      "Обработка online_shoppers - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 18 колонок\n",
      "  Сохранено в ../datasets/online_shoppers/online_shoppers_ohe.csv\n",
      "  Новый размер: 10000 строк, 122 колонок\n",
      "  Запись для 'one_hot_encoding' обновлена в ../datasets/online_shoppers/data.csv\n",
      "\n",
      "Обработка phishing_websites - One-Hot Encoding...\n",
      "  Загружено 10000 строк, 31 колонок\n",
      "  Сохранено в ../datasets/phishing_websites/phishing_websites_ohe.csv\n",
      "  Новый размер: 10000 строк, 69 колонок\n",
      "  Запись для 'one_hot_encoding' обновлена в ../datasets/phishing_websites/data.csv\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:47.814512Z",
     "start_time": "2025-12-04T05:47:46.706013Z"
    }
   },
   "source": [
    "# Применяем Label Encoding\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LABEL ENCODING\")\n",
    "print(\"=\"*50)\n",
    "label_encoding(datasets)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LABEL ENCODING\n",
      "==================================================\n",
      "\n",
      "Обработка adult - Label Encoding...\n",
      "  Загружено 10000 строк, 15 колонок\n",
      "  Сохранено в ../datasets/adult/adult_label.csv\n",
      "  Размер: 10000 строк, 15 колонок\n",
      "  Закодированные колонки: ['workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'class']\n",
      "  Запись для 'label_encoding' обновлена в ../datasets/adult/data.csv\n",
      "\n",
      "Обработка bank_marketing - Label Encoding...\n",
      "  Загружено 10000 строк, 17 колонок\n",
      "  Сохранено в ../datasets/bank_marketing/bank_marketing_label.csv\n",
      "  Размер: 10000 строк, 17 колонок\n",
      "  Закодированные колонки: ['V2', 'V3', 'V4', 'V5', 'V7', 'V8', 'V9', 'V10', 'V11', 'V13', 'V15', 'V16', 'Class']\n",
      "  Запись для 'label_encoding' обновлена в ../datasets/bank_marketing/data.csv\n",
      "\n",
      "Обработка california_housing - Label Encoding...\n",
      "  Загружено 10000 строк, 9 колонок\n",
      "  Пропущен: нет категориальных признаков кроме target\n",
      "\n",
      "Обработка chess_kr_k - Label Encoding...\n",
      "  Загружено 1473 строк, 10 колонок\n",
      "  Сохранено в ../datasets/chess_kr_k/chess_kr_k_label.csv\n",
      "  Размер: 1473 строк, 10 колонок\n",
      "  Закодированные колонки: ['Wifes_age', 'Wifes_education', 'Husbands_education', 'Number_of_children_ever_born', 'Wifes_religion', 'Wifes_now_working%3F', 'Husbands_occupation', 'Standard-of-living_index', 'Media_exposure', 'Contraceptive_method_used']\n",
      "  Запись для 'label_encoding' обновлена в ../datasets/chess_kr_k/data.csv\n",
      "\n",
      "Обработка connect_4 - Label Encoding...\n",
      "  Загружено 10000 строк, 43 колонок\n",
      "  Сохранено в ../datasets/connect_4/connect_4_label.csv\n",
      "  Размер: 10000 строк, 43 колонок\n",
      "  Закодированные колонки: ['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'class']\n",
      "  Запись для 'label_encoding' обновлена в ../datasets/connect_4/data.csv\n",
      "\n",
      "Обработка default_credit - Label Encoding...\n",
      "  Загружено 10000 строк, 24 колонок\n",
      "  Сохранено в ../datasets/default_credit/default_credit_label.csv\n",
      "  Размер: 10000 строк, 24 колонок\n",
      "  Закодированные колонки: ['x2', 'x3', 'x4', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'y']\n",
      "  Запись для 'label_encoding' обновлена в ../datasets/default_credit/data.csv\n",
      "\n",
      "Обработка letter_recognition - Label Encoding...\n",
      "  Загружено 10000 строк, 17 колонок\n",
      "  Сохранено в ../datasets/letter_recognition/letter_recognition_label.csv\n",
      "  Размер: 10000 строк, 17 колонок\n",
      "  Закодированные колонки: ['x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx', 'class']\n",
      "  Запись для 'label_encoding' обновлена в ../datasets/letter_recognition/data.csv\n",
      "\n",
      "Обработка magic_gamma - Label Encoding...\n",
      "  Загружено 10000 строк, 11 колонок\n",
      "  Пропущен: нет категориальных признаков кроме target\n",
      "\n",
      "Обработка nursery - Label Encoding...\n",
      "  Загружено 10000 строк, 9 колонок\n",
      "  Сохранено в ../datasets/nursery/nursery_label.csv\n",
      "  Размер: 10000 строк, 9 колонок\n",
      "  Закодированные колонки: ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health', 'class']\n",
      "  Запись для 'label_encoding' обновлена в ../datasets/nursery/data.csv\n",
      "\n",
      "Обработка online_shoppers - Label Encoding...\n",
      "  Загружено 10000 строк, 18 колонок\n",
      "  Сохранено в ../datasets/online_shoppers/online_shoppers_label.csv\n",
      "  Размер: 10000 строк, 18 колонок\n",
      "  Закодированные колонки: ['Administrative', 'Informational', 'SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend', 'Revenue']\n",
      "  Запись для 'label_encoding' обновлена в ../datasets/online_shoppers/data.csv\n",
      "\n",
      "Обработка phishing_websites - Label Encoding...\n",
      "  Загружено 10000 строк, 31 колонок\n",
      "  Сохранено в ../datasets/phishing_websites/phishing_websites_label.csv\n",
      "  Размер: 10000 строк, 31 колонок\n",
      "  Закодированные колонки: ['having_IP_Address', 'URL_Length', 'Shortining_Service', 'having_At_Symbol', 'double_slash_redirecting', 'Prefix_Suffix', 'having_Sub_Domain', 'SSLfinal_State', 'Domain_registeration_length', 'Favicon', 'port', 'HTTPS_token', 'Request_URL', 'URL_of_Anchor', 'Links_in_tags', 'SFH', 'Submitting_to_email', 'Abnormal_URL', 'Redirect', 'on_mouseover', 'RightClick', 'popUpWidnow', 'Iframe', 'age_of_domain', 'DNSRecord', 'web_traffic', 'Page_Rank', 'Google_Index', 'Links_pointing_to_page', 'Statistical_report', 'Result']\n",
      "  Запись для 'label_encoding' обновлена в ../datasets/phishing_websites/data.csv\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:49.186386Z",
     "start_time": "2025-12-04T05:47:47.847939Z"
    }
   },
   "source": [
    "# Применяем Frequency Encoding\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FREQUENCY ENCODING\")\n",
    "print(\"=\"*50)\n",
    "frequency_encoding(datasets)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FREQUENCY ENCODING\n",
      "==================================================\n",
      "\n",
      "Обработка adult - Frequency Encoding...\n",
      "  Загружено 10000 строк, 15 колонок\n",
      "  Сохранено в ../datasets/adult/adult_frequency.csv\n",
      "  Размер: 10000 строк, 15 колонок\n",
      "  Закодированные колонки: ['workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'class']\n",
      "  Запись для 'frequency_encoding' обновлена в ../datasets/adult/data.csv\n",
      "\n",
      "Обработка bank_marketing - Frequency Encoding...\n",
      "  Загружено 10000 строк, 17 колонок\n",
      "  Сохранено в ../datasets/bank_marketing/bank_marketing_frequency.csv\n",
      "  Размер: 10000 строк, 17 колонок\n",
      "  Закодированные колонки: ['V2', 'V3', 'V4', 'V5', 'V7', 'V8', 'V9', 'V10', 'V11', 'V13', 'V15', 'V16', 'Class']\n",
      "  Запись для 'frequency_encoding' обновлена в ../datasets/bank_marketing/data.csv\n",
      "\n",
      "Обработка california_housing - Frequency Encoding...\n",
      "  Загружено 10000 строк, 9 колонок\n",
      "  Пропущен: нет категориальных признаков кроме target\n",
      "\n",
      "Обработка chess_kr_k - Frequency Encoding...\n",
      "  Загружено 1473 строк, 10 колонок\n",
      "  Сохранено в ../datasets/chess_kr_k/chess_kr_k_frequency.csv\n",
      "  Размер: 1473 строк, 10 колонок\n",
      "  Закодированные колонки: ['Wifes_age', 'Wifes_education', 'Husbands_education', 'Number_of_children_ever_born', 'Wifes_religion', 'Wifes_now_working%3F', 'Husbands_occupation', 'Standard-of-living_index', 'Media_exposure', 'Contraceptive_method_used']\n",
      "  Запись для 'frequency_encoding' обновлена в ../datasets/chess_kr_k/data.csv\n",
      "\n",
      "Обработка connect_4 - Frequency Encoding...\n",
      "  Загружено 10000 строк, 43 колонок\n",
      "  Сохранено в ../datasets/connect_4/connect_4_frequency.csv\n",
      "  Размер: 10000 строк, 43 колонок\n",
      "  Закодированные колонки: ['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'class']\n",
      "  Запись для 'frequency_encoding' обновлена в ../datasets/connect_4/data.csv\n",
      "\n",
      "Обработка default_credit - Frequency Encoding...\n",
      "  Загружено 10000 строк, 24 колонок\n",
      "  Сохранено в ../datasets/default_credit/default_credit_frequency.csv\n",
      "  Размер: 10000 строк, 24 колонок\n",
      "  Закодированные колонки: ['x2', 'x3', 'x4', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'y']\n",
      "  Запись для 'frequency_encoding' обновлена в ../datasets/default_credit/data.csv\n",
      "\n",
      "Обработка letter_recognition - Frequency Encoding...\n",
      "  Загружено 10000 строк, 17 колонок\n",
      "  Сохранено в ../datasets/letter_recognition/letter_recognition_frequency.csv\n",
      "  Размер: 10000 строк, 17 колонок\n",
      "  Закодированные колонки: ['x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx', 'class']\n",
      "  Запись для 'frequency_encoding' обновлена в ../datasets/letter_recognition/data.csv\n",
      "\n",
      "Обработка magic_gamma - Frequency Encoding...\n",
      "  Загружено 10000 строк, 11 колонок\n",
      "  Пропущен: нет категориальных признаков кроме target\n",
      "\n",
      "Обработка nursery - Frequency Encoding...\n",
      "  Загружено 10000 строк, 9 колонок\n",
      "  Сохранено в ../datasets/nursery/nursery_frequency.csv\n",
      "  Размер: 10000 строк, 9 колонок\n",
      "  Закодированные колонки: ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health', 'class']\n",
      "  Запись для 'frequency_encoding' обновлена в ../datasets/nursery/data.csv\n",
      "\n",
      "Обработка online_shoppers - Frequency Encoding...\n",
      "  Загружено 10000 строк, 18 колонок\n",
      "  Сохранено в ../datasets/online_shoppers/online_shoppers_frequency.csv\n",
      "  Размер: 10000 строк, 18 колонок\n",
      "  Закодированные колонки: ['Administrative', 'Informational', 'SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend', 'Revenue']\n",
      "  Запись для 'frequency_encoding' обновлена в ../datasets/online_shoppers/data.csv\n",
      "\n",
      "Обработка phishing_websites - Frequency Encoding...\n",
      "  Загружено 10000 строк, 31 колонок\n",
      "  Сохранено в ../datasets/phishing_websites/phishing_websites_frequency.csv\n",
      "  Размер: 10000 строк, 31 колонок\n",
      "  Закодированные колонки: ['having_IP_Address', 'URL_Length', 'Shortining_Service', 'having_At_Symbol', 'double_slash_redirecting', 'Prefix_Suffix', 'having_Sub_Domain', 'SSLfinal_State', 'Domain_registeration_length', 'Favicon', 'port', 'HTTPS_token', 'Request_URL', 'URL_of_Anchor', 'Links_in_tags', 'SFH', 'Submitting_to_email', 'Abnormal_URL', 'Redirect', 'on_mouseover', 'RightClick', 'popUpWidnow', 'Iframe', 'age_of_domain', 'DNSRecord', 'web_traffic', 'Page_Rank', 'Google_Index', 'Links_pointing_to_page', 'Statistical_report', 'Result']\n",
      "  Запись для 'frequency_encoding' обновлена в ../datasets/phishing_websites/data.csv\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:49.991015Z",
     "start_time": "2025-12-04T05:47:49.227142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Применяем Original Encoding\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ORIGINAL ENCODING\")\n",
    "print(\"=\"*50)\n",
    "original_encoding(datasets)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ORIGINAL ENCODING\n",
      "==================================================\n",
      "\n",
      "Обработка adult - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 15 колонок\n",
      "  Целевая колонка 'class' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/adult/adult_original.csv\n",
      "  Размер: 10000 строк, 15 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/adult/data.csv\n",
      "\n",
      "Обработка bank_marketing - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 17 колонок\n",
      "  Целевая колонка 'Class' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/bank_marketing/bank_marketing_original.csv\n",
      "  Размер: 10000 строк, 17 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/bank_marketing/data.csv\n",
      "\n",
      "Обработка california_housing - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 9 колонок\n",
      "  Целевая колонка 'MedHouseVal' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/california_housing/california_housing_original.csv\n",
      "  Размер: 10000 строк, 9 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/california_housing/data.csv\n",
      "\n",
      "Обработка chess_kr_k - Original (только target закодирован)...\n",
      "  Загружено 1473 строк, 10 колонок\n",
      "  Целевая колонка 'Contraceptive_method_used' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/chess_kr_k/chess_kr_k_original.csv\n",
      "  Размер: 1473 строк, 10 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/chess_kr_k/data.csv\n",
      "\n",
      "Обработка connect_4 - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 43 колонок\n",
      "  Целевая колонка 'class' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/connect_4/connect_4_original.csv\n",
      "  Размер: 10000 строк, 43 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/connect_4/data.csv\n",
      "\n",
      "Обработка default_credit - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 24 колонок\n",
      "  Целевая колонка 'y' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/default_credit/default_credit_original.csv\n",
      "  Размер: 10000 строк, 24 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/default_credit/data.csv\n",
      "\n",
      "Обработка letter_recognition - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 17 колонок\n",
      "  Целевая колонка 'class' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/letter_recognition/letter_recognition_original.csv\n",
      "  Размер: 10000 строк, 17 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/letter_recognition/data.csv\n",
      "\n",
      "Обработка magic_gamma - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 11 колонок\n",
      "  Целевая колонка 'class:' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/magic_gamma/magic_gamma_original.csv\n",
      "  Размер: 10000 строк, 11 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/magic_gamma/data.csv\n",
      "\n",
      "Обработка nursery - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 9 колонок\n",
      "  Целевая колонка 'class' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/nursery/nursery_original.csv\n",
      "  Размер: 10000 строк, 9 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/nursery/data.csv\n",
      "\n",
      "Обработка online_shoppers - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 18 колонок\n",
      "  Целевая колонка 'Revenue' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/online_shoppers/online_shoppers_original.csv\n",
      "  Размер: 10000 строк, 18 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/online_shoppers/data.csv\n",
      "\n",
      "Обработка phishing_websites - Original (только target закодирован)...\n",
      "  Загружено 10000 строк, 31 колонок\n",
      "  Целевая колонка 'Result' закодирована с помощью LabelEncoder\n",
      "  Сохранено в ../datasets/phishing_websites/phishing_websites_original.csv\n",
      "  Размер: 10000 строк, 31 колонок\n",
      "  Закодированные колонки: []\n",
      "  Запись для 'original' обновлена в ../datasets/phishing_websites/data.csv\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Проверка результатов"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:50.149059Z",
     "start_time": "2025-12-04T05:47:50.141029Z"
    }
   },
   "source": [
    "# Просмотр обновленного data.csv для датасета adult\n",
    "data_csv_path = '../datasets/adult/data.csv'\n",
    "if os.path.exists(data_csv_path):\n",
    "    result_df = pd.read_csv(data_csv_path)\n",
    "    print(f\"Содержимое {data_csv_path}:\")\n",
    "    result_df.head()\n",
    "else:\n",
    "    print(f\"Файл {data_csv_path} не найден\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Содержимое ../datasets/adult/data.csv:\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:50.203081Z",
     "start_time": "2025-12-04T05:47:50.189707Z"
    }
   },
   "cell_type": "code",
   "source": "result_df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               method                                path  \\\n",
       "0    one_hot_encoding        datasets/adult/adult_ohe.csv   \n",
       "1      label_encoding      datasets/adult/adult_label.csv   \n",
       "2  frequency_encoding  datasets/adult/adult_frequency.csv   \n",
       "3            original   datasets/adult/adult_original.csv   \n",
       "\n",
       "                                        New_cat_cols  model_path  \\\n",
       "0  ['workclass_Federal-gov', 'workclass_Local-gov...         NaN   \n",
       "1  ['workclass', 'education', 'education-num', 'm...         NaN   \n",
       "2  ['workclass', 'education', 'education-num', 'm...         NaN   \n",
       "3                                                 []         NaN   \n",
       "\n",
       "   schedul_path  JS divergence  Utility_XGBoost  Utility_logistic_r  \\\n",
       "0           NaN            NaN              NaN                 NaN   \n",
       "1           NaN            NaN              NaN                 NaN   \n",
       "2           NaN            NaN              NaN                 NaN   \n",
       "3           NaN            NaN              NaN                 NaN   \n",
       "\n",
       "   matrix_distance  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>path</th>\n",
       "      <th>New_cat_cols</th>\n",
       "      <th>model_path</th>\n",
       "      <th>schedul_path</th>\n",
       "      <th>JS divergence</th>\n",
       "      <th>Utility_XGBoost</th>\n",
       "      <th>Utility_logistic_r</th>\n",
       "      <th>matrix_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one_hot_encoding</td>\n",
       "      <td>datasets/adult/adult_ohe.csv</td>\n",
       "      <td>['workclass_Federal-gov', 'workclass_Local-gov...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>label_encoding</td>\n",
       "      <td>datasets/adult/adult_label.csv</td>\n",
       "      <td>['workclass', 'education', 'education-num', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frequency_encoding</td>\n",
       "      <td>datasets/adult/adult_frequency.csv</td>\n",
       "      <td>['workclass', 'education', 'education-num', 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original</td>\n",
       "      <td>datasets/adult/adult_original.csv</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:47:50.277561Z",
     "start_time": "2025-12-04T05:47:50.258048Z"
    }
   },
   "source": [
    "# Сравнение размеров датасетов\n",
    "print(\"\\nСравнение размеров датасетов:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for dataset_info in datasets:\n",
    "    dataset_folder = Path(dataset_info['dataset_csv']).parent\n",
    "    dataset_name = dataset_info['dataset_name']\n",
    "    \n",
    "    print(f\"\\n{dataset_name.upper()}:\")\n",
    "    \n",
    "    # Оригинальный датасет\n",
    "    if os.path.exists(dataset_info['dataset_path']):\n",
    "        df_orig = pd.read_csv(dataset_info['dataset_path'])\n",
    "        print(f\"  Оригинал:    {df_orig.shape[0]:>6} строк × {df_orig.shape[1]:>3} колонок\")\n",
    "    \n",
    "    # OHE\n",
    "    ohe_path = dataset_folder / f\"{dataset_name}_ohe.csv\"\n",
    "    if os.path.exists(ohe_path):\n",
    "        df_ohe = pd.read_csv(ohe_path)\n",
    "        print(f\"  OHE:         {df_ohe.shape[0]:>6} строк × {df_ohe.shape[1]:>3} колонок\")\n",
    "    \n",
    "    # Label\n",
    "    label_path = dataset_folder / f\"{dataset_name}_label.csv\"\n",
    "    if os.path.exists(label_path):\n",
    "        df_label = pd.read_csv(label_path)\n",
    "        print(f\"  Label:       {df_label.shape[0]:>6} строк × {df_label.shape[1]:>3} колонок\")\n",
    "    \n",
    "    # Frequency\n",
    "    freq_path = dataset_folder / f\"{dataset_name}_frequency.csv\"\n",
    "    if os.path.exists(freq_path):\n",
    "        df_freq = pd.read_csv(freq_path)\n",
    "        print(f\"  Frequency:   {df_freq.shape[0]:>6} строк × {df_freq.shape[1]:>3} колонок\")\n",
    "\n",
    "    # Original\n",
    "    orig_path = dataset_folder / f\"{dataset_name}_original.csv\"\n",
    "    if os.path.exists(orig_path):\n",
    "        df_orig_enc = pd.read_csv(orig_path)\n",
    "        print(f\"  Original:    {df_orig_enc.shape[0]:>6} строк × {df_orig_enc.shape[1]:>3} колонок\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сравнение размеров датасетов:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ADULT:\n",
      "\n",
      "BANK_MARKETING:\n",
      "\n",
      "CALIFORNIA_HOUSING:\n",
      "\n",
      "CHESS_KR_K:\n",
      "\n",
      "CONNECT_4:\n",
      "\n",
      "DEFAULT_CREDIT:\n",
      "\n",
      "LETTER_RECOGNITION:\n",
      "\n",
      "MAGIC_GAMMA:\n",
      "\n",
      "NURSERY:\n",
      "\n",
      "ONLINE_SHOPPERS:\n",
      "\n",
      "PHISHING_WEBSITES:\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
